{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "239743d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e48118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e72e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42300b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7efeccfb1750>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 5\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8863b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.seq_list1 = list(df['Wspd_seq'])\n",
    "        self.seq_list2 = list(df['Patv_seq'])\n",
    "        \n",
    "        self.seq_list3 = list(df['Etmp_seq'])\n",
    "        self.seq_list4 = list(df['Itmp_seq'])\n",
    "        \n",
    "        self.seq_list5 = list(df['Patv_space'])\n",
    "\n",
    "        \n",
    "        self.label_list = df.target.values\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        seq = np.vstack((self.seq_list1[index], self.seq_list2[index], self.seq_list3[index], self.seq_list4[index]))\n",
    "        seq = np.array(seq).astype('float')\n",
    "        \n",
    "        image = np.array(self.seq_list5[index]).astype('float') \n",
    "        image.resize(11, 11, 1)\n",
    "\n",
    "        label = np.array( self.label_list[index] ).astype( 'float' )\n",
    "        \n",
    "        seq = torch.tensor(seq, device = 'cuda')\n",
    "        space_data = torch.tensor(image, device = 'cuda')\n",
    "\n",
    "        return seq, space_data, label\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aaf8b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool of square window of size=3, stride=2\n",
    "m = nn.MaxPool2d(3, stride=2)\n",
    "# pool of non-square window\n",
    "m = nn.MaxPool2d((3, 3))\n",
    "input = torch.randn(20, 16, 10,10)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "245bbcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 16, 3, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a3af1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRU, self).__init__()\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=4, hidden_size=48, num_layers=2)\n",
    "        self.dropout = nn.Dropout(0.05)\n",
    "\n",
    "#         self.Linear = nn.Linear(48+2, 1, bias_attr=True)\n",
    "        self.Linear = nn.Linear(48+2, 1)\n",
    "\n",
    "        self.cnnLayer = nn.Sequential(\n",
    "        nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1), \n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.GELU(),\n",
    "        nn.MaxPool2d((3,3)))\n",
    "\n",
    "        \n",
    "    def forward(self, X, space_data):\n",
    "\n",
    "        z = torch.zeros([X.shape[0], 144, X.shape[1]])\n",
    "        z = z.to(device)\n",
    "#         print(X.shape)\n",
    "#         print(z)\n",
    "#         print(type(x))\n",
    "#         print(type(X))\n",
    "#         print(type(z))\n",
    "        x = torch.concat((torch.transpose(X,2,1),z), axis=1)\n",
    "#         print(1)\n",
    "        out1, _ = self.gru(x)\n",
    "        ou1 = self.dropout(out1)\n",
    "\n",
    "        cnn_out = self.cnnLayer(space_data)\n",
    "        print('cnn_out')\n",
    "        print(cnn_out.shape)\n",
    "        cnn_out = torch.reshape(cnn_out, (cnn_out.shape[0], 288, -1))\n",
    "        print(cnn_out.shape)\n",
    "#         print(cnn_out.shape)\n",
    "        out2 = self.Linear(torch.concat((out1, cnn_out), 2))\n",
    "\n",
    "       \n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1178a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train_data42.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f4953ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72ea98a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def func(obj):\n",
    "    List = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        List.append(i)\n",
    "    return List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f24f6cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Wspd_seq'] = df_train['Wspd_seq'].apply(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4240bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0.29, 0.59, 0.97, 1.38, 1.94, 2.23, 2.54, 1.8...\n",
       "1        [1.62, 1.15, 1.84, 2.42, 1.72, 1.75, 1.75, 2.9...\n",
       "2        [2.67, 2.75, 2.65, 2.66, 2.42, 2.31, 2.04, 2.1...\n",
       "3        [11.25, 10.66, 10.63, 9.57, 10.14, 9.93, 9.13,...\n",
       "4        [4.52, 3.73, 3.6, 3.49, 3.03, 2.82, 3.56, 3.54...\n",
       "                               ...                        \n",
       "37044    [7.07, 7.26, 7.55, 7.57, 7.72, 7.71, 7.05, 7.1...\n",
       "37045    [3.25, 2.18, 2.09, 1.97, 2.17, 2.37, 2.16, 1.4...\n",
       "37046    [1.84, 3.88, 4.39, 3.72, 3.91, 3.86, 4.47, 2.9...\n",
       "37047    [6.32, 5.96, 6.11, 5.59, 5.0, 5.12, 5.3, 5.9, ...\n",
       "37048    [6.67, 5.74, 6.91, 5.13, 4.51, 6.54, 6.37, 5.6...\n",
       "Name: Wspd_seq, Length: 37049, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Wspd_seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b152b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Wspd_seq'] = df_train.apply(\n",
    "  lambda x: [round(r**3,4) for r in x['Wspd_seq']],\n",
    "  axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bfef86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0.0244, 0.2054, 0.9127, 2.6281, 7.3014, 11.08...\n",
       "1        [4.2515, 1.5209, 6.2295, 14.1725, 5.0884, 5.35...\n",
       "2        [19.0342, 20.7969, 18.6096, 18.8211, 14.1725, ...\n",
       "3        [1423.8281, 1211.3555, 1201.157, 876.4675, 104...\n",
       "4        [92.3454, 51.8951, 46.656, 42.5085, 27.8181, 2...\n",
       "                               ...                        \n",
       "37044    [353.3932, 382.6572, 430.3689, 433.7981, 460.0...\n",
       "37045    [34.3281, 10.3602, 9.1293, 7.6454, 10.2183, 13...\n",
       "37046    [6.2295, 58.4111, 84.6045, 51.4788, 59.7765, 5...\n",
       "37047    [252.436, 211.7087, 228.0991, 174.6769, 125.0,...\n",
       "37048    [296.741, 189.1192, 329.9394, 135.0057, 91.733...\n",
       "Name: Wspd_seq, Length: 37049, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Wspd_seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cc46748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'----------------------------------------------------------------------------------'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'----------------------------------------------------------------------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b84afe3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wspd_seq</th>\n",
       "      <th>Patv_seq</th>\n",
       "      <th>Etmp_seq</th>\n",
       "      <th>Itmp_seq</th>\n",
       "      <th>Pab1_seq</th>\n",
       "      <th>target</th>\n",
       "      <th>index</th>\n",
       "      <th>TurbID</th>\n",
       "      <th>Patv_space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0244, 0.2054, 0.9127, 2.6281, 7.3014, 11.08...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[21.84, 21.77, 21.81, 21.9, 21.9, 21.87, 21.81...</td>\n",
       "      <td>[26.78, 26.7, 26.55, 26.47, 26.15, 25.75, 25.6...</td>\n",
       "      <td>[90.39, 90.39, 90.39, 90.39, 90.39, 90.39, 90....</td>\n",
       "      <td>[1422.04, 1519.51, 1501.53, 1519.98, 1519.36, ...</td>\n",
       "      <td>21207</td>\n",
       "      <td>14</td>\n",
       "      <td>[1194.55, 1411.22, 1519.46, 1515.86, 1447.61, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4.2515, 1.5209, 6.2295, 14.1725, 5.0884, 5.35...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.31, 86....</td>\n",
       "      <td>[43.73, 42.19, 42.09, 42.09, 42.02, 41.95, 41....</td>\n",
       "      <td>[42.02, 43.59, 44.67, 44.6, 44.43, 44.28, 44.2...</td>\n",
       "      <td>[43.31, 90.39, 90.39, 90.39, 90.39, 90.39, 90....</td>\n",
       "      <td>[209.79, 247.88, 371.06, 183.73, 194.71, 132.3...</td>\n",
       "      <td>9625</td>\n",
       "      <td>118</td>\n",
       "      <td>[155.11, 190.08, 153.1, 197.71, 143.08, 155.7,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[19.0342, 20.7969, 18.6096, 18.8211, 14.1725, ...</td>\n",
       "      <td>[110.84, 111.16, 103.88, 96.08, 87.81, 88.23, ...</td>\n",
       "      <td>[17.06, 17.05, 16.99, 16.96, 16.79, 16.58, 16....</td>\n",
       "      <td>[17.0, 16.98, 16.84, 16.79, 16.7, 16.63, 16.57...</td>\n",
       "      <td>[-1.99, -1.99, -1.99, -1.99, -1.99, -1.99, -1....</td>\n",
       "      <td>[80.74, 77.03, 100.68, 1.18, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>20781</td>\n",
       "      <td>126</td>\n",
       "      <td>[100.73, 86.67, 83.81, 92.14, 107.54, 117.99, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1423.8281, 1211.3555, 1201.157, 876.4675, 104...</td>\n",
       "      <td>[1033.06, 1039.58, 1302.54, 1262.94, 1350.97, ...</td>\n",
       "      <td>[37.17, 37.38, 37.4, 37.36, 37.46, 37.7, 37.58...</td>\n",
       "      <td>[41.37, 41.55, 41.87, 42.06, 42.3, 42.5, 42.75...</td>\n",
       "      <td>[9.35, 8.41, 4.81, 1.91, 2.17, 2.04, 1.2, 0.61...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>16070</td>\n",
       "      <td>103</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[92.3454, 51.8951, 46.656, 42.5085, 27.8181, 2...</td>\n",
       "      <td>[232.71, 152.88, 132.2, 118.21, 53.07, 69.46, ...</td>\n",
       "      <td>[17.73, 17.64, 17.46, 17.35, 17.14, 16.99, 16....</td>\n",
       "      <td>[18.23, 18.14, 18.02, 17.93, 18.33, 19.89, 20....</td>\n",
       "      <td>[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.0...</td>\n",
       "      <td>[104.76, 96.46, 128.23, 128.2, 113.63, 85.32, ...</td>\n",
       "      <td>24026</td>\n",
       "      <td>117</td>\n",
       "      <td>[178.41, 241.21, 151.74, 0.0, 184.48, 242.99, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37044</th>\n",
       "      <td>[353.3932, 382.6572, 430.3689, 433.7981, 460.0...</td>\n",
       "      <td>[755.06, 742.34, 790.33, 773.86, 791.98, 703.8...</td>\n",
       "      <td>[324.56, 324.56, 324.56, 324.56, 324.56, 324.5...</td>\n",
       "      <td>[16.12, 16.13, 16.3, 16.31, 16.3, 16.3, 16.11,...</td>\n",
       "      <td>[0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.42...</td>\n",
       "      <td>26081</td>\n",
       "      <td>67</td>\n",
       "      <td>[0.0, 0.0, 0.0, 143.76, 111.39, 209.05, 148.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37045</th>\n",
       "      <td>[34.3281, 10.3602, 9.1293, 7.6454, 10.2183, 13...</td>\n",
       "      <td>[107.14, 31.96, 35.2, 37.22, 52.73, 50.69, 41....</td>\n",
       "      <td>[39.02, 39.67, 40.05, 39.09, 38.69, 39.59, 39....</td>\n",
       "      <td>[39.79, 40.3, 41.93, 41.37, 40.44, 41.48, 42.4...</td>\n",
       "      <td>[0.07, 0.05, 0.04, 0.02, 0.01, 0.01, 0.01, 0.0...</td>\n",
       "      <td>[448.04, 366.33, 318.85, 503.17, 327.75, 358.7...</td>\n",
       "      <td>10203</td>\n",
       "      <td>110</td>\n",
       "      <td>[445.67, 487.56, 451.39, 491.9, 568.12, 436.23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37046</th>\n",
       "      <td>[6.2295, 58.4111, 84.6045, 51.4788, 59.7765, 5...</td>\n",
       "      <td>[0.0, 67.83, 217.08, 150.25, 163.84, 167.28, 2...</td>\n",
       "      <td>[31.1, 31.44, 31.22, 31.09, 31.0, 30.84, 30.62...</td>\n",
       "      <td>[37.39, 37.47, 37.48, 37.3, 37.16, 36.92, 36.7...</td>\n",
       "      <td>[51.17, 29.55, 0.01, 0.01, 0.01, 0.01, 0.01, 0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 122.54, 134.98, 64.59, 53.01, ...</td>\n",
       "      <td>15671</td>\n",
       "      <td>107</td>\n",
       "      <td>[0.0, 0.0, 0.0, 32.49, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37047</th>\n",
       "      <td>[252.436, 211.7087, 228.0991, 174.6769, 125.0,...</td>\n",
       "      <td>[650.06, 490.62, 500.19, 466.35, 355.16, 377.4...</td>\n",
       "      <td>[20.79, 20.69, 20.59, 20.41, 20.27, 20.23, 20....</td>\n",
       "      <td>[37.39, 37.24, 37.19, 37.09, 37.09, 37.01, 36....</td>\n",
       "      <td>[0.01, 3.14, 3.09, 1.87, 3.06, 3.1, 2.92, 3.78...</td>\n",
       "      <td>[343.52, 324.64, 462.57, 798.65, 644.13, 441.4...</td>\n",
       "      <td>19585</td>\n",
       "      <td>125</td>\n",
       "      <td>[449.34, 276.97, 409.61, 451.46, 437.52, 451.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37048</th>\n",
       "      <td>[296.741, 189.1192, 329.9394, 135.0057, 91.733...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 82.56, 133.23, 363.76, 398.75,...</td>\n",
       "      <td>[28.91, 29.14, 29.4, 29.6, 29.79, 30.08, 29.55...</td>\n",
       "      <td>[29.83, 30.17, 30.42, 30.69, 31.03, 31.63, 31....</td>\n",
       "      <td>[90.17, 90.17, 90.17, 44.32, 1.25, 1.69, 0.98,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 109.43, 13...</td>\n",
       "      <td>2088</td>\n",
       "      <td>84</td>\n",
       "      <td>[6.67, 0.0, 75.76, 0.0, 124.73, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37049 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Wspd_seq  \\\n",
       "0      [0.0244, 0.2054, 0.9127, 2.6281, 7.3014, 11.08...   \n",
       "1      [4.2515, 1.5209, 6.2295, 14.1725, 5.0884, 5.35...   \n",
       "2      [19.0342, 20.7969, 18.6096, 18.8211, 14.1725, ...   \n",
       "3      [1423.8281, 1211.3555, 1201.157, 876.4675, 104...   \n",
       "4      [92.3454, 51.8951, 46.656, 42.5085, 27.8181, 2...   \n",
       "...                                                  ...   \n",
       "37044  [353.3932, 382.6572, 430.3689, 433.7981, 460.0...   \n",
       "37045  [34.3281, 10.3602, 9.1293, 7.6454, 10.2183, 13...   \n",
       "37046  [6.2295, 58.4111, 84.6045, 51.4788, 59.7765, 5...   \n",
       "37047  [252.436, 211.7087, 228.0991, 174.6769, 125.0,...   \n",
       "37048  [296.741, 189.1192, 329.9394, 135.0057, 91.733...   \n",
       "\n",
       "                                                Patv_seq  \\\n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.31, 86....   \n",
       "2      [110.84, 111.16, 103.88, 96.08, 87.81, 88.23, ...   \n",
       "3      [1033.06, 1039.58, 1302.54, 1262.94, 1350.97, ...   \n",
       "4      [232.71, 152.88, 132.2, 118.21, 53.07, 69.46, ...   \n",
       "...                                                  ...   \n",
       "37044  [755.06, 742.34, 790.33, 773.86, 791.98, 703.8...   \n",
       "37045  [107.14, 31.96, 35.2, 37.22, 52.73, 50.69, 41....   \n",
       "37046  [0.0, 67.83, 217.08, 150.25, 163.84, 167.28, 2...   \n",
       "37047  [650.06, 490.62, 500.19, 466.35, 355.16, 377.4...   \n",
       "37048  [0.0, 0.0, 0.0, 82.56, 133.23, 363.76, 398.75,...   \n",
       "\n",
       "                                                Etmp_seq  \\\n",
       "0      [21.84, 21.77, 21.81, 21.9, 21.9, 21.87, 21.81...   \n",
       "1      [43.73, 42.19, 42.09, 42.09, 42.02, 41.95, 41....   \n",
       "2      [17.06, 17.05, 16.99, 16.96, 16.79, 16.58, 16....   \n",
       "3      [37.17, 37.38, 37.4, 37.36, 37.46, 37.7, 37.58...   \n",
       "4      [17.73, 17.64, 17.46, 17.35, 17.14, 16.99, 16....   \n",
       "...                                                  ...   \n",
       "37044  [324.56, 324.56, 324.56, 324.56, 324.56, 324.5...   \n",
       "37045  [39.02, 39.67, 40.05, 39.09, 38.69, 39.59, 39....   \n",
       "37046  [31.1, 31.44, 31.22, 31.09, 31.0, 30.84, 30.62...   \n",
       "37047  [20.79, 20.69, 20.59, 20.41, 20.27, 20.23, 20....   \n",
       "37048  [28.91, 29.14, 29.4, 29.6, 29.79, 30.08, 29.55...   \n",
       "\n",
       "                                                Itmp_seq  \\\n",
       "0      [26.78, 26.7, 26.55, 26.47, 26.15, 25.75, 25.6...   \n",
       "1      [42.02, 43.59, 44.67, 44.6, 44.43, 44.28, 44.2...   \n",
       "2      [17.0, 16.98, 16.84, 16.79, 16.7, 16.63, 16.57...   \n",
       "3      [41.37, 41.55, 41.87, 42.06, 42.3, 42.5, 42.75...   \n",
       "4      [18.23, 18.14, 18.02, 17.93, 18.33, 19.89, 20....   \n",
       "...                                                  ...   \n",
       "37044  [16.12, 16.13, 16.3, 16.31, 16.3, 16.3, 16.11,...   \n",
       "37045  [39.79, 40.3, 41.93, 41.37, 40.44, 41.48, 42.4...   \n",
       "37046  [37.39, 37.47, 37.48, 37.3, 37.16, 36.92, 36.7...   \n",
       "37047  [37.39, 37.24, 37.19, 37.09, 37.09, 37.01, 36....   \n",
       "37048  [29.83, 30.17, 30.42, 30.69, 31.03, 31.63, 31....   \n",
       "\n",
       "                                                Pab1_seq  \\\n",
       "0      [90.39, 90.39, 90.39, 90.39, 90.39, 90.39, 90....   \n",
       "1      [43.31, 90.39, 90.39, 90.39, 90.39, 90.39, 90....   \n",
       "2      [-1.99, -1.99, -1.99, -1.99, -1.99, -1.99, -1....   \n",
       "3      [9.35, 8.41, 4.81, 1.91, 2.17, 2.04, 1.2, 0.61...   \n",
       "4      [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.0...   \n",
       "...                                                  ...   \n",
       "37044  [0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0...   \n",
       "37045  [0.07, 0.05, 0.04, 0.02, 0.01, 0.01, 0.01, 0.0...   \n",
       "37046  [51.17, 29.55, 0.01, 0.01, 0.01, 0.01, 0.01, 0...   \n",
       "37047  [0.01, 3.14, 3.09, 1.87, 3.06, 3.1, 2.92, 3.78...   \n",
       "37048  [90.17, 90.17, 90.17, 44.32, 1.25, 1.69, 0.98,...   \n",
       "\n",
       "                                                  target  index  TurbID  \\\n",
       "0      [1422.04, 1519.51, 1501.53, 1519.98, 1519.36, ...  21207      14   \n",
       "1      [209.79, 247.88, 371.06, 183.73, 194.71, 132.3...   9625     118   \n",
       "2      [80.74, 77.03, 100.68, 1.18, 0.0, 0.0, 0.0, 0....  20781     126   \n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  16070     103   \n",
       "4      [104.76, 96.46, 128.23, 128.2, 113.63, 85.32, ...  24026     117   \n",
       "...                                                  ...    ...     ...   \n",
       "37044  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.42...  26081      67   \n",
       "37045  [448.04, 366.33, 318.85, 503.17, 327.75, 358.7...  10203     110   \n",
       "37046  [0.0, 0.0, 0.0, 122.54, 134.98, 64.59, 53.01, ...  15671     107   \n",
       "37047  [343.52, 324.64, 462.57, 798.65, 644.13, 441.4...  19585     125   \n",
       "37048  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 109.43, 13...   2088      84   \n",
       "\n",
       "                                              Patv_space  \n",
       "0      [1194.55, 1411.22, 1519.46, 1515.86, 1447.61, ...  \n",
       "1      [155.11, 190.08, 153.1, 197.71, 143.08, 155.7,...  \n",
       "2      [100.73, 86.67, 83.81, 92.14, 107.54, 117.99, ...  \n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4      [178.41, 241.21, 151.74, 0.0, 184.48, 242.99, ...  \n",
       "...                                                  ...  \n",
       "37044  [0.0, 0.0, 0.0, 143.76, 111.39, 209.05, 148.18...  \n",
       "37045  [445.67, 487.56, 451.39, 491.9, 568.12, 436.23...  \n",
       "37046  [0.0, 0.0, 0.0, 32.49, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "37047  [449.34, 276.97, 409.61, 451.46, 437.52, 451.2...  \n",
       "37048  [6.67, 0.0, 75.76, 0.0, 124.73, 0.0, 0.0, 0.0,...  \n",
       "\n",
       "[37049 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "330e5158",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Pab1_seq'] = df_train['Pab1_seq'].apply(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0de51e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Pab1_seq'] = df_train.apply(\n",
    "  lambda x: [round(np.sin((2*np.pi*r)/360),4) for r in x['Pab1_seq']],\n",
    "  axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01f0b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "def my_scale(lst):\n",
    "    n = len(lst)\n",
    "    x = np.array(lst).reshape(-1,1)\n",
    "    scaler_robust = RobustScaler()\n",
    "    scaler_robust.fit(x)\n",
    "    k = scaler_robust.transform(x)\n",
    "    kk = k.reshape(n)\n",
    "    return list(np.round(kk, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5737f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Patv_seq'] = df_train['Patv_seq'].apply(func)\n",
    "df_train['Etmp_seq'] = df_train['Etmp_seq'].apply(func)\n",
    "df_train['Itmp_seq'] = df_train['Itmp_seq'].apply(func)\n",
    "# df_train['Patv_space'] = df_train['Patv_space'].apply(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "375dd381",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Wspd_seq'] = df_train['Wspd_seq'].apply(lambda x : my_scale(x))\n",
    "df_train['Patv_seq'] = df_train['Patv_seq'].apply(lambda x : my_scale(x))\n",
    "df_train['Etmp_seq'] = df_train['Etmp_seq'].apply(lambda x : my_scale(x))\n",
    "df_train['Itmp_seq'] = df_train['Itmp_seq'].apply(lambda x : my_scale(x))\n",
    "# df_train['Patv_space'] = df_train['Patv_space'].apply(lambda x : my_scale(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a522c3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wspd_seq</th>\n",
       "      <th>Patv_seq</th>\n",
       "      <th>Etmp_seq</th>\n",
       "      <th>Itmp_seq</th>\n",
       "      <th>Pab1_seq</th>\n",
       "      <th>target</th>\n",
       "      <th>index</th>\n",
       "      <th>TurbID</th>\n",
       "      <th>Patv_space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.1743, -0.1737, -0.1715, -0.1662, -0.1516, ...</td>\n",
       "      <td>[-0.1833, -0.1833, -0.1833, -0.1833, -0.1833, ...</td>\n",
       "      <td>[-0.4851, -0.4942, -0.489, -0.4773, -0.4773, -...</td>\n",
       "      <td>[-0.3207, -0.3332, -0.3567, -0.3693, -0.4194, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1422.04, 1519.51, 1501.53, 1519.98, 1519.36, ...</td>\n",
       "      <td>21207</td>\n",
       "      <td>14</td>\n",
       "      <td>[1194.55, 1411.22, 1519.46, 1515.86, 1447.61, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.3364, -0.3964, -0.293, -0.1186, -0.318, -0...</td>\n",
       "      <td>[-0.3675, -0.3675, -0.3675, -0.3675, -0.3675, ...</td>\n",
       "      <td>[0.5691, 0.426, 0.4167, 0.4167, 0.4102, 0.4037...</td>\n",
       "      <td>[0.5655, 0.8317, 1.0148, 1.003, 0.9741, 0.9487...</td>\n",
       "      <td>[0.6859, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5885,...</td>\n",
       "      <td>[209.79, 247.88, 371.06, 183.73, 194.71, 132.3...</td>\n",
       "      <td>9625</td>\n",
       "      <td>118</td>\n",
       "      <td>[155.11, 190.08, 153.1, 197.71, 143.08, 155.7,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.1565, 0.2133, 0.1429, 0.1497, 0.0, -0.0594,...</td>\n",
       "      <td>[0.5605, 0.5629, 0.5083, 0.4499, 0.3879, 0.391...</td>\n",
       "      <td>[-1.5684, -1.5704, -1.5824, -1.5884, -1.6224, ...</td>\n",
       "      <td>[-1.7724, -1.777, -1.809, -1.8205, -1.8411, -1...</td>\n",
       "      <td>[-0.0347, -0.0347, -0.0347, -0.0347, -0.0347, ...</td>\n",
       "      <td>[80.74, 77.03, 100.68, 1.18, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>20781</td>\n",
       "      <td>126</td>\n",
       "      <td>[100.73, 86.67, 83.81, 92.14, 107.54, 117.99, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2.4374, 2.041, 2.022, 1.4162, 1.7261, 1.6078,...</td>\n",
       "      <td>[0.9856, 0.9944, 1.3484, 1.2951, 1.4136, 1.330...</td>\n",
       "      <td>[0.6354, 0.6546, 0.6565, 0.6528, 0.6619, 0.683...</td>\n",
       "      <td>[0.5507, 0.5682, 0.5992, 0.6176, 0.6408, 0.660...</td>\n",
       "      <td>[0.1625, 0.1463, 0.0839, 0.0333, 0.0379, 0.035...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>16070</td>\n",
       "      <td>103</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.9007, 0.8426, 0.7056, 0.5971, 0.2128, 0.071...</td>\n",
       "      <td>[2.2655, 1.4883, 1.287, 1.1508, 0.5166, 0.6762...</td>\n",
       "      <td>[0.2288, 0.2155, 0.1887, 0.1724, 0.1412, 0.118...</td>\n",
       "      <td>[-0.1278, -0.1495, -0.1784, -0.2001, -0.1037, ...</td>\n",
       "      <td>[0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.000...</td>\n",
       "      <td>[104.76, 96.46, 128.23, 128.2, 113.63, 85.32, ...</td>\n",
       "      <td>24026</td>\n",
       "      <td>117</td>\n",
       "      <td>[178.41, 241.21, 151.74, 0.0, 184.48, 242.99, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37044</th>\n",
       "      <td>[-0.1038, -0.0443, 0.0528, 0.0598, 0.1133, 0.1...</td>\n",
       "      <td>[0.2628, 0.2462, 0.309, 0.2875, 0.3112, 0.1958...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.66, -0.6574, -0.6121, -0.6094, -0.6121, -0...</td>\n",
       "      <td>[0.0003, 0.0003, 0.0002, 0.0002, 0.0002, 0.000...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.42...</td>\n",
       "      <td>26081</td>\n",
       "      <td>67</td>\n",
       "      <td>[0.0, 0.0, 0.0, 143.76, 111.39, 209.05, 148.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37045</th>\n",
       "      <td>[0.4636, 0.0118, -0.0114, -0.0393, 0.0092, 0.0...</td>\n",
       "      <td>[0.9904, 0.2954, 0.3254, 0.344, 0.4874, 0.4686...</td>\n",
       "      <td>[0.5474, 0.7004, 0.7899, 0.5639, 0.4697, 0.681...</td>\n",
       "      <td>[0.3869, 0.5679, 1.1464, 0.9476, 0.6176, 0.986...</td>\n",
       "      <td>[0.0012, 0.0009, 0.0007, 0.0003, 0.0002, 0.000...</td>\n",
       "      <td>[448.04, 366.33, 318.85, 503.17, 327.75, 358.7...</td>\n",
       "      <td>10203</td>\n",
       "      <td>110</td>\n",
       "      <td>[445.67, 487.56, 451.39, 491.9, 568.12, 436.23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37046</th>\n",
       "      <td>[-0.0763, 1.635, 2.4941, 1.4077, 1.6798, 1.605...</td>\n",
       "      <td>[0.0, 0.581, 1.8593, 1.2869, 1.4033, 1.4327, 1...</td>\n",
       "      <td>[0.4809, 0.5269, 0.4971, 0.4795, 0.4674, 0.445...</td>\n",
       "      <td>[0.4828, 0.4946, 0.4961, 0.4695, 0.4489, 0.413...</td>\n",
       "      <td>[0.779, 0.4932, 0.0002, 0.0002, 0.0002, 0.0002...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 122.54, 134.98, 64.59, 53.01, ...</td>\n",
       "      <td>15671</td>\n",
       "      <td>107</td>\n",
       "      <td>[0.0, 0.0, 0.0, 32.49, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37047</th>\n",
       "      <td>[1.243, 0.9332, 1.0579, 0.6515, 0.2737, 0.3438...</td>\n",
       "      <td>[1.2121, 0.6981, 0.729, 0.6199, 0.2614, 0.3334...</td>\n",
       "      <td>[-0.3457, -0.3646, -0.3834, -0.4173, -0.4437, ...</td>\n",
       "      <td>[0.7514, 0.6676, 0.6397, 0.5838, 0.5838, 0.539...</td>\n",
       "      <td>[0.0002, 0.0548, 0.0539, 0.0326, 0.0534, 0.054...</td>\n",
       "      <td>[343.52, 324.64, 462.57, 798.65, 644.13, 441.4...</td>\n",
       "      <td>19585</td>\n",
       "      <td>125</td>\n",
       "      <td>[449.34, 276.97, 409.61, 451.46, 437.52, 451.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37048</th>\n",
       "      <td>[1.4164, 0.8234, 1.5993, 0.5253, 0.2869, 1.322...</td>\n",
       "      <td>[-0.25, -0.25, -0.25, 0.0093, 0.1684, 0.8925, ...</td>\n",
       "      <td>[-0.234, -0.1603, -0.0769, -0.0128, 0.0481, 0....</td>\n",
       "      <td>[-0.8454, -0.7624, -0.7013, -0.6353, -0.5522, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.6987, 0.0218, 0.0295, 0.0171...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 109.43, 13...</td>\n",
       "      <td>2088</td>\n",
       "      <td>84</td>\n",
       "      <td>[6.67, 0.0, 75.76, 0.0, 124.73, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37049 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Wspd_seq  \\\n",
       "0      [-0.1743, -0.1737, -0.1715, -0.1662, -0.1516, ...   \n",
       "1      [-0.3364, -0.3964, -0.293, -0.1186, -0.318, -0...   \n",
       "2      [0.1565, 0.2133, 0.1429, 0.1497, 0.0, -0.0594,...   \n",
       "3      [2.4374, 2.041, 2.022, 1.4162, 1.7261, 1.6078,...   \n",
       "4      [1.9007, 0.8426, 0.7056, 0.5971, 0.2128, 0.071...   \n",
       "...                                                  ...   \n",
       "37044  [-0.1038, -0.0443, 0.0528, 0.0598, 0.1133, 0.1...   \n",
       "37045  [0.4636, 0.0118, -0.0114, -0.0393, 0.0092, 0.0...   \n",
       "37046  [-0.0763, 1.635, 2.4941, 1.4077, 1.6798, 1.605...   \n",
       "37047  [1.243, 0.9332, 1.0579, 0.6515, 0.2737, 0.3438...   \n",
       "37048  [1.4164, 0.8234, 1.5993, 0.5253, 0.2869, 1.322...   \n",
       "\n",
       "                                                Patv_seq  \\\n",
       "0      [-0.1833, -0.1833, -0.1833, -0.1833, -0.1833, ...   \n",
       "1      [-0.3675, -0.3675, -0.3675, -0.3675, -0.3675, ...   \n",
       "2      [0.5605, 0.5629, 0.5083, 0.4499, 0.3879, 0.391...   \n",
       "3      [0.9856, 0.9944, 1.3484, 1.2951, 1.4136, 1.330...   \n",
       "4      [2.2655, 1.4883, 1.287, 1.1508, 0.5166, 0.6762...   \n",
       "...                                                  ...   \n",
       "37044  [0.2628, 0.2462, 0.309, 0.2875, 0.3112, 0.1958...   \n",
       "37045  [0.9904, 0.2954, 0.3254, 0.344, 0.4874, 0.4686...   \n",
       "37046  [0.0, 0.581, 1.8593, 1.2869, 1.4033, 1.4327, 1...   \n",
       "37047  [1.2121, 0.6981, 0.729, 0.6199, 0.2614, 0.3334...   \n",
       "37048  [-0.25, -0.25, -0.25, 0.0093, 0.1684, 0.8925, ...   \n",
       "\n",
       "                                                Etmp_seq  \\\n",
       "0      [-0.4851, -0.4942, -0.489, -0.4773, -0.4773, -...   \n",
       "1      [0.5691, 0.426, 0.4167, 0.4167, 0.4102, 0.4037...   \n",
       "2      [-1.5684, -1.5704, -1.5824, -1.5884, -1.6224, ...   \n",
       "3      [0.6354, 0.6546, 0.6565, 0.6528, 0.6619, 0.683...   \n",
       "4      [0.2288, 0.2155, 0.1887, 0.1724, 0.1412, 0.118...   \n",
       "...                                                  ...   \n",
       "37044  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "37045  [0.5474, 0.7004, 0.7899, 0.5639, 0.4697, 0.681...   \n",
       "37046  [0.4809, 0.5269, 0.4971, 0.4795, 0.4674, 0.445...   \n",
       "37047  [-0.3457, -0.3646, -0.3834, -0.4173, -0.4437, ...   \n",
       "37048  [-0.234, -0.1603, -0.0769, -0.0128, 0.0481, 0....   \n",
       "\n",
       "                                                Itmp_seq  \\\n",
       "0      [-0.3207, -0.3332, -0.3567, -0.3693, -0.4194, ...   \n",
       "1      [0.5655, 0.8317, 1.0148, 1.003, 0.9741, 0.9487...   \n",
       "2      [-1.7724, -1.777, -1.809, -1.8205, -1.8411, -1...   \n",
       "3      [0.5507, 0.5682, 0.5992, 0.6176, 0.6408, 0.660...   \n",
       "4      [-0.1278, -0.1495, -0.1784, -0.2001, -0.1037, ...   \n",
       "...                                                  ...   \n",
       "37044  [-0.66, -0.6574, -0.6121, -0.6094, -0.6121, -0...   \n",
       "37045  [0.3869, 0.5679, 1.1464, 0.9476, 0.6176, 0.986...   \n",
       "37046  [0.4828, 0.4946, 0.4961, 0.4695, 0.4489, 0.413...   \n",
       "37047  [0.7514, 0.6676, 0.6397, 0.5838, 0.5838, 0.539...   \n",
       "37048  [-0.8454, -0.7624, -0.7013, -0.6353, -0.5522, ...   \n",
       "\n",
       "                                                Pab1_seq  \\\n",
       "0      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1      [0.6859, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5885,...   \n",
       "2      [-0.0347, -0.0347, -0.0347, -0.0347, -0.0347, ...   \n",
       "3      [0.1625, 0.1463, 0.0839, 0.0333, 0.0379, 0.035...   \n",
       "4      [0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.000...   \n",
       "...                                                  ...   \n",
       "37044  [0.0003, 0.0003, 0.0002, 0.0002, 0.0002, 0.000...   \n",
       "37045  [0.0012, 0.0009, 0.0007, 0.0003, 0.0002, 0.000...   \n",
       "37046  [0.779, 0.4932, 0.0002, 0.0002, 0.0002, 0.0002...   \n",
       "37047  [0.0002, 0.0548, 0.0539, 0.0326, 0.0534, 0.054...   \n",
       "37048  [1.0, 1.0, 1.0, 0.6987, 0.0218, 0.0295, 0.0171...   \n",
       "\n",
       "                                                  target  index  TurbID  \\\n",
       "0      [1422.04, 1519.51, 1501.53, 1519.98, 1519.36, ...  21207      14   \n",
       "1      [209.79, 247.88, 371.06, 183.73, 194.71, 132.3...   9625     118   \n",
       "2      [80.74, 77.03, 100.68, 1.18, 0.0, 0.0, 0.0, 0....  20781     126   \n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  16070     103   \n",
       "4      [104.76, 96.46, 128.23, 128.2, 113.63, 85.32, ...  24026     117   \n",
       "...                                                  ...    ...     ...   \n",
       "37044  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.42...  26081      67   \n",
       "37045  [448.04, 366.33, 318.85, 503.17, 327.75, 358.7...  10203     110   \n",
       "37046  [0.0, 0.0, 0.0, 122.54, 134.98, 64.59, 53.01, ...  15671     107   \n",
       "37047  [343.52, 324.64, 462.57, 798.65, 644.13, 441.4...  19585     125   \n",
       "37048  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 109.43, 13...   2088      84   \n",
       "\n",
       "                                              Patv_space  \n",
       "0      [1194.55, 1411.22, 1519.46, 1515.86, 1447.61, ...  \n",
       "1      [155.11, 190.08, 153.1, 197.71, 143.08, 155.7,...  \n",
       "2      [100.73, 86.67, 83.81, 92.14, 107.54, 117.99, ...  \n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4      [178.41, 241.21, 151.74, 0.0, 184.48, 242.99, ...  \n",
       "...                                                  ...  \n",
       "37044  [0.0, 0.0, 0.0, 143.76, 111.39, 209.05, 148.18...  \n",
       "37045  [445.67, 487.56, 451.39, 491.9, 568.12, 436.23...  \n",
       "37046  [0.0, 0.0, 0.0, 32.49, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "37047  [449.34, 276.97, 409.61, 451.46, 437.52, 451.2...  \n",
       "37048  [6.67, 0.0, 75.76, 0.0, 124.73, 0.0, 0.0, 0.0,...  \n",
       "\n",
       "[37049 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5efa8c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_train[:-3700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b97a106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = df_train[-3700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc5161c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "cols = [x for x in train_df.columns if 'seq' in x or x=='target' or x=='Patv_space']\n",
    "for col in cols:\n",
    "    train_df[col] = train_df[col].apply(lambda x: json.loads(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ec02e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "cols = [x for x in val_df.columns if 'seq' in x or x=='target' or x=='Patv_space']\n",
    "for col in cols:\n",
    "    val_df[col] = val_df[col].apply(lambda x: json.loads(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7d3f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = myDataset(train_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                      batch_size=32,\n",
    "                      shuffle=False,\n",
    "                      num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dafb9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = myDataset(val_df)\n",
    "\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                      batch_size=32,\n",
    "                      shuffle=False,\n",
    "                      num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aef71dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f71fb547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    metric = nn.L1Loss().to(device)\n",
    "\n",
    "    ls = []\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "    val_loss_lst = []\n",
    "    val_mae_lst = []\n",
    "    loss_list = []\n",
    "    early_stopping = EarlyStopping(patience = 5, verbose = True)\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "\n",
    "        for seq, space_data, label in tqdm(train_loader):\n",
    "            seq = seq.type(torch.float32).to(device)\n",
    "\n",
    "            space_data = torch.reshape(space_data, (-1,1,11,11 )).to(device)\n",
    "            space_data = space_data.type(torch.float32)\n",
    "    \n",
    "            label = label.type(torch.float32).to(device)\n",
    "\n",
    "            pred = model(seq, space_data)\n",
    "\n",
    "            loss = criterion(pred.squeeze()/1000, label/1000)\n",
    "            loss_list.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_list.extend(pred.squeeze().cpu().detach().numpy())\n",
    "            label_list.extend(label.squeeze().cpu().detach().numpy())\n",
    "            \n",
    "            del pred \n",
    "            del seq\n",
    "            del space_data\n",
    "            del label\n",
    "            \n",
    "        for val_seq, val_space_data, val_label in tqdm(val_loader):\n",
    "            val_seq = val_seq.type(torch.float32).to(device)\n",
    "            val_space_data = torch.reshape(val_space_data, (-1,1,11,11 )).to(device)\n",
    "            val_space_data = val_space_data.type(torch.float32)\n",
    "    \n",
    "            val_label = val_label.type(torch.float32)\n",
    "            val_pred = model(val_seq, val_space_data).cpu()\n",
    "\n",
    "\n",
    "            val_loss = criterion(val_pred.squeeze()/1000, val_label/1000)\n",
    "            with torch.no_grad():\n",
    "                val_mae = metric(val_pred.squeeze(), val_label)\n",
    "            val_loss_lst.append(val_loss.item())\n",
    "            val_mae_lst.append(val_mae)\n",
    "\n",
    "            \n",
    "        val_mae = np.average(val_mae_lst)\n",
    "        \n",
    "        early_stopping(val_mae,model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "\n",
    "        total_loss = torch.mean(torch.tensor(loss_list, device = 'cuda'))\n",
    "#         model.eval()\n",
    "\n",
    "        print(\n",
    "            f'Epoch: {epoch} Loss: {total_loss}'\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    torch.save(model.state_dict(), './ourbest2batch32shuffleF3sin_data_normal_lr05scaling22yeswspdscale.pdparams', _use_new_zipfile_serialization=False)\n",
    "    print('Model Saved.')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6c12efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/1043 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                               | 3/1043 [00:13<1:02:09,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                                | 11/1043 [00:14<10:27,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                               | 24/1043 [00:14<02:55,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███                                                                              | 39/1043 [00:14<01:13, 13.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▎                                                                            | 55/1043 [00:14<00:37, 26.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████                                                                           | 78/1043 [00:14<00:19, 50.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▋                                                                        | 101/1043 [00:15<00:12, 72.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▌                                                                      | 125/1043 [00:15<00:10, 89.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▎                                                                    | 147/1043 [00:15<00:09, 98.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▉                                                                  | 171/1043 [00:15<00:08, 104.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▌                                                                | 193/1043 [00:15<00:07, 106.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████████████                                                               | 222/1043 [00:16<00:59, 13.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n",
      "cnn_out\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 288, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_87/3432553824.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_87/913701968.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_loader, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#             print(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_87/1248738445.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_list1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_list2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_list3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_list4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;31m# raise warning if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0m_arrays_for_stack_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36matleast_2d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36matleast_2d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GRU()\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0005)\n",
    "train(model, optimizer, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6077797d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cf8b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4307f75c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
